{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# add project root folder to path to allow import local modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# import local modules\n",
    "from helpers import compute_ridge_loss\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Quantiles = 200\n",
    "Quantile_Transformer = True\n",
    "Logarithm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make custom pipeline to create normal distributions for the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Transformation_Preprocessing(Preprocessing):\n",
    "    def __init__(self,dataset):\n",
    "        super().__init__(dataset)\n",
    "        self.n_quantiles = None\n",
    "        self.quantile_transformer = None\n",
    "        self.logarithm = None\n",
    "        self.indexes= None\n",
    "    \n",
    "    def set_transformation_configuration(self,n_quantiles, quantile_transformer, logarithm, indexes):\n",
    "        self.n_quantiles = n_quantiles\n",
    "        self.quantile_transformer = quantile_transformer\n",
    "        self.logarithm = logarithm\n",
    "        self.indexes = indexes\n",
    "        \n",
    "    def _feature_transformation(self):\n",
    "        super()._feature_transformation() \n",
    "        \n",
    "        dataset =self.dataset\n",
    "        \n",
    "        if self.logarithm:\n",
    "            for i in self.indexes:\n",
    "                #print('before : ', self.dataset[:,i])\n",
    "                self.dataset[:,i] = np.array([np.sign(x)*np.log(1+ abs(x)) for x in dataset[:,i]])             \n",
    "                #print('after:', self.dataset[:,i])\n",
    "        \n",
    "        if self.quantile_transformer:\n",
    "            for i in self.indexes:\n",
    "                qt = QuantileTransformer(self.n_quantiles, output_distribution= 'normal')\n",
    "                new_feature = qt.fit_transform(self.dataset[:,i].reshape(-1,1))\n",
    "                self.dataset[:,i] = new_feature.flatten()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = Feature_Transformation_Preprocessing(load_csv('../dataset/trainset.csv'))\n",
    "p_test = Feature_Transformation_Preprocessing(load_csv('../dataset/testset.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train.set_transformation_configuration(N_Quantiles, Quantile_Transformer, Logarithm, np.array([1,3,9,10,13,16,21,23,29]))\n",
    "p_test.set_transformation_configuration(N_Quantiles, Quantile_Transformer, Logarithm, np.array([1,3,9,10,13,16,21,23,29]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/Users/Clement/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_quantiles=100 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train , x_train= p_train.preprocess()\n",
    "y_test, x_test = p_test.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000, 31)\n",
      "(25000, 31)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weight, x_test, boundary = 0.5):\n",
    "    \"\"\"\n",
    "    # Gives predictions given weight and datapoints \n",
    "    \n",
    "    :param weight: vector weight\n",
    "    :type weight: 1D array\n",
    "    \n",
    "    :param x_test: extended feature matrix\n",
    "    :type x_test: 2D array\n",
    "    \n",
    "    :return: label predictions (0 or 1)\n",
    "    :rtype:  1D numpy array\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pred = x_test.dot(weight)\n",
    "    return (pred > boundary)*1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08379648216603008\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(y_train, x_train,0.004)\n",
    "#print(w) # gives an idea about the important columns.. \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def K_Cross_Validation(x, y, K, _lambda):\n",
    "    #Initialization of all needed arrays\n",
    "    test_loss = np.zeros(K)\n",
    "    train_loss = np.zeros(K)\n",
    "    weights = np.zeros((K,x.shape[1]))\n",
    "    accuracy = np.zeros(K)\n",
    "    indices = build_k_indices(y, K)\n",
    "    \n",
    "    for i in range(K):\n",
    "        test_indices = indices[i]\n",
    "        y_test = y[test_indices]\n",
    "        y_train = np.delete(y,test_indices)\n",
    "        x_test = x[test_indices,:]\n",
    "        x_train = np.delete(x,test_indices,axis=0)\n",
    "        ### ADAPT METHOD & LOSS\n",
    "        weights[i], train_loss[i] = ridge_regression(y_train, x_train,_lambda)\n",
    "        test_loss[i] = compute_ridge_loss(y_test,x_test,weights[i],_lambda)\n",
    "        \n",
    "        #Calculate predictions of the model\n",
    "        predictions = predict(weights[i] , x_test)\n",
    "        #Calculate accuracy of the model\n",
    "        accuracy[i] = np.sum(predictions == y_test) / len(y_test)\n",
    "        \n",
    "    return accuracy, test_loss, train_loss, np.mean(weights, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542444444444444\n",
      "[0.08308221 0.08321067 0.08354256 0.08317456]\n",
      "[0.08327403 0.08323345 0.08312022 0.08324508]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs,test_loss, train_loss, w = K_Cross_Validation(x_train,y_train,4,0.001)\n",
    "plt.boxplot(accs)\n",
    "print(accs.mean())\n",
    "print(test_loss)\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal acc = 0.7401333333333333 with lambda= 1e-07\n"
     ]
    }
   ],
   "source": [
    "def Tune_lambda(xt_training, y_training, K, gamma_range):\n",
    "        \n",
    "    lambdas = np.logspace(-7, gamma_range, 10)\n",
    "    max_acc = 0\n",
    "    min_loss = np.inf\n",
    "    opt_lambda = 0\n",
    "    accuracies = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i, lambda_ in enumerate(lambdas):\n",
    "       \n",
    "        accuracy,test,train,w = K_Cross_Validation(xt_training, y_training, K,lambda_)\n",
    "        accuracies.append([lambda_,np.median(accuracy)])\n",
    "        train_losses.append([lambda_,np.median(train)])\n",
    "        test_losses.append([lambda_,np.median(test)])\n",
    "        if (np.median(test) < min_loss):\n",
    "            min_loss = np.median(test)\n",
    "            max_acc = np.median(accuracy)\n",
    "            opt_lambda = lambda_\n",
    "                \n",
    "    return opt_lambda , max_acc, np.array(accuracies), np.array(train_losses), np.array(test_losses)\n",
    "opt_lambda, max_acc, acc ,train, test= Tune_lambda(x_train, y_train, 5, 1)\n",
    "\n",
    "print(f\"optimal acc = {max_acc} with lambda= {opt_lambda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_opt,loss = ridge_regression(y_train,x_train,0.00001)\n",
    "p = predict(w_opt,x_test)\n",
    "print((p==y_test).mean())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
