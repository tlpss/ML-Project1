{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# add project root folder to path to allow import local modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# import local modules\n",
    "from helpers import compute_ridge_loss\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Quantiles = 100\n",
    "Quantile_Transformer = False\n",
    "Box_Cox= True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make custom pipeline to create normal distributions for the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution_Transform_Preprocessing(Preprocessing):\n",
    "    def __init__(self,dataset):\n",
    "        super().__init__(dataset)\n",
    "        self.n_quantiles = None\n",
    "        self.quantile_transformer = None\n",
    "        self.box_cox= None\n",
    "    \n",
    "    def set_dist_quantiles(self,n_quantiles, quantile_transformer, box_cox):\n",
    "        self.n_quantiles = n_quantiles\n",
    "        self.quantile_transformer = quantile_transformer\n",
    "        self.box_cox = box_cox\n",
    "        \n",
    "        \n",
    "    def _feature_engineering(self):\n",
    "        super()._feature_engineering() \n",
    "        \n",
    "        dataset =self.dataset\n",
    "        \n",
    "        if self.quantile_transformer:\n",
    "            for i in range(self.dataset.shape[1]):\n",
    "                qt = QuantileTransformer(self.n_quantiles, output_distribution= 'normal')\n",
    "                new_feature = qt.fit_transform(self.dataset[:,i].reshape(-1,1))\n",
    "                self.dataset[:,i] = new_feature.flatten()\n",
    "        \n",
    "        if self.box_cox:\n",
    "            for i in range(dataset.shape[1]):\n",
    "                min_feature = np.min(dataset[:,i])\n",
    "                \n",
    "                if (min_feature<0):\n",
    "                    dataset[:,i] = np.array([x + np.abs(min_feature) + 1 for x in dataset[:,i]])\n",
    "                    \n",
    "                bc = PowerTransformer(method='box-cox')\n",
    "                new_feature = bc.fit_transform(dataset[:,i].reshape(-1,1))\n",
    "                self.dataset[:,i] = new_feature.flatten()\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = Distribution_Transform_Preprocessing(load_csv('../dataset/trainset.csv'))\n",
    "p_test = Distribution_Transform_Preprocessing(load_csv('../dataset/testset.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train.set_dist_quantiles(N_Quantiles, Quantile_Transformer, Box_Cox)\n",
    "p_test.set_dist_quantiles(N_Quantiles, Quantile_Transformer, Box_Cox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train , x_train= p_train.preprocess()\n",
    "y_test, x_test = p_test.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000, 31)\n",
      "(25000, 31)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weight, x_test, boundary = 0.5):\n",
    "    \"\"\"\n",
    "    # Gives predictions given weight and datapoints \n",
    "    \n",
    "    :param weight: vector weight\n",
    "    :type weight: 1D array\n",
    "    \n",
    "    :param x_test: extended feature matrix\n",
    "    :type x_test: 2D array\n",
    "    \n",
    "    :return: label predictions (0 or 1)\n",
    "    :rtype:  1D numpy array\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pred = x_test.dot(weight)\n",
    "    return (pred > boundary)*1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08548384238253409\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(y_train, x_train,0.004)\n",
    "#print(w) # gives an idea about the important columns.. \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "def K_Cross_Validation(x, y, K, _lambda):\n",
    "    #Initialization of all needed arrays\n",
    "    test_loss = np.zeros(K)\n",
    "    train_loss = np.zeros(K)\n",
    "    weights = np.zeros((K,x.shape[1]))\n",
    "    accuracy = np.zeros(K)\n",
    "    indices = build_k_indices(y, K)\n",
    "    \n",
    "    for i in range(K):\n",
    "        test_indices = indices[i]\n",
    "        y_test = y[test_indices]\n",
    "        y_train = np.delete(y,test_indices)\n",
    "        x_test = x[test_indices,:]\n",
    "        x_train = np.delete(x,test_indices,axis=0)\n",
    "        ### ADAPT METHOD & LOSS\n",
    "        weights[i], train_loss[i] = ridge_regression(y_train, x_train,_lambda)\n",
    "        test_loss[i] = compute_ridge_loss(y_test,x_test,weights[i],_lambda)\n",
    "        \n",
    "        #Calculate predictions of the model\n",
    "        predictions = predict(weights[i] , x_test)\n",
    "        #Calculate accuracy of the model\n",
    "        accuracy[i] = np.sum(predictions == y_test) / len(y_test)\n",
    "        \n",
    "    return accuracy, test_loss, train_loss, np.mean(weights, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7457911111111112\n",
      "[0.08483932 0.08499527 0.08476635 0.08529177]\n",
      "[0.08497566 0.08492436 0.08499751 0.08482817]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs,test_loss, train_loss, w = K_Cross_Validation(x_train,y_train,4,0.001)\n",
    "plt.boxplot(accs)\n",
    "print(accs.mean())\n",
    "print(test_loss)\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal acc = 0.7462888888888889 with lambda= 1e-07\n"
     ]
    }
   ],
   "source": [
    "def Tune_lambda(xt_training, y_training, K, gamma_range):\n",
    "        \n",
    "    lambdas = np.logspace(-7, gamma_range, 10)\n",
    "    max_acc = 0\n",
    "    min_loss = np.inf\n",
    "    opt_lambda = 0\n",
    "    accuracies = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i, lambda_ in enumerate(lambdas):\n",
    "       \n",
    "        accuracy,test,train,w = K_Cross_Validation(xt_training, y_training, K,lambda_)\n",
    "        accuracies.append([lambda_,np.median(accuracy)])\n",
    "        train_losses.append([lambda_,np.median(train)])\n",
    "        test_losses.append([lambda_,np.median(test)])\n",
    "        if (np.median(test) < min_loss):\n",
    "            min_loss = np.median(test)\n",
    "            max_acc = np.median(accuracy)\n",
    "            opt_lambda = lambda_\n",
    "                \n",
    "    return opt_lambda , max_acc, np.array(accuracies), np.array(train_losses), np.array(test_losses)\n",
    "opt_lambda, max_acc, acc ,train, test= Tune_lambda(x_train, y_train, 5, 1)\n",
    "\n",
    "print(f\"optimal acc = {max_acc} with lambda= {opt_lambda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75036\n",
      "0.08474172818686453\n"
     ]
    }
   ],
   "source": [
    "w_opt,loss = ridge_regression(y_train,x_train,0.00001)\n",
    "p = predict(w_opt,x_test)\n",
    "print((p==y_test).mean())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
