{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T09:22:34.533405Z",
     "start_time": "2020-10-07T09:22:34.530412Z"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T09:22:45.445833Z",
     "start_time": "2020-10-07T09:22:34.970056Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_csv('dataset/trainset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T15:10:01.531772Z",
     "start_time": "2020-09-27T15:10:01.528814Z"
    }
   },
   "source": [
    "### extract predictions, discard IDs and transform to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:19.597805Z",
     "start_time": "2020-09-27T18:29:19.593813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225000\n",
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "\n",
    "y = dataset[\"Prediction\"]\n",
    "print(len(y))\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:21.297251Z",
     "start_time": "2020-09-27T18:29:20.486458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000, 30)\n",
      "[-9.9900e+02  9.0100e+01  4.4395e+01  1.7740e+00 -9.9900e+02 -9.9900e+02\n",
      " -9.9900e+02  1.3770e+00  1.7740e+00  6.4763e+01  1.3700e+00 -1.3950e+00\n",
      " -9.9900e+02  2.7323e+01 -5.7400e-01  1.4570e+00  3.7440e+01 -1.5850e+00\n",
      "  5.2100e-01  5.6246e+01 -2.2370e+00  9.3023e+01  0.0000e+00 -9.9900e+02\n",
      " -9.9900e+02 -9.9900e+02 -9.9900e+02 -9.9900e+02 -9.9900e+02  0.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "# remove id & predictions, convert to 2D ndarray\n",
    "data = np.array(dataset.tolist()) # not efficient, but it does the job and is still < 1s \n",
    "data = data[:,2:]\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate means of valid points & replace missing points by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:23.326835Z",
     "start_time": "2020-09-27T18:29:23.281948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, 90.1, 44.395, ..., --, --, 0.0],\n",
       "        [28.478, 52.063, 21.773, ..., --, --, 50.076],\n",
       "        [74.538, 119.834, 66.795, ..., -0.449, 0.57, 71.123],\n",
       "        ...,\n",
       "        [62.328, 42.916, 44.607, ..., --, --, 51.348],\n",
       "        [133.204, 17.066, 54.913, ..., -0.128, -2.185, 205.491],\n",
       "        [--, 72.435, 59.817, ..., --, --, 0.0]],\n",
       "  mask=[[ True, False, False, ...,  True,  True, False],\n",
       "        [False, False, False, ...,  True,  True, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ...,  True,  True, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [ True, False, False, ...,  True,  True, False]],\n",
       "  fill_value=1e+20)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create masked ndarray to discard missing values\n",
    "# https://numpy.org/doc/stable/reference/maskedarray.generic.html#constructing-masked-arrays\n",
    "mask = data == -999.0\n",
    "masked_data = np.ma.array(data)\n",
    "masked_data.mask = mask\n",
    "masked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:24.338123Z",
     "start_time": "2020-09-27T18:29:24.264319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.21787311e+02,  4.91733179e+01,  8.11552019e+01,  5.80110215e+01,\n",
       "        2.40016552e+00,  3.71544546e+02, -8.12847295e-01,  2.37200843e+00,\n",
       "        1.89338249e+01,  1.58561722e+02,  1.43750899e+00, -1.26627596e-01,\n",
       "        4.58146191e-01,  3.87136342e+01, -1.09434622e-02, -8.72947111e-03,\n",
       "        4.66526434e+01, -2.01354978e-02,  4.26294311e-02,  4.17174179e+01,\n",
       "       -1.17773333e-02,  2.09980447e+02,  9.80426667e-01,  8.48992350e+01,\n",
       "       -5.90535272e-03, -1.12831502e-02,  5.77031093e+01, -1.11501667e-02,\n",
       "       -3.14898920e-03,  7.31954449e+01])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.ma.mean(masked_data, axis = 0)\n",
    "means.shape\n",
    "means.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:25.096921Z",
     "start_time": "2020-09-27T18:29:25.009119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.007993771258043e-11 0.0 0.0 0.0 6.780354055990756e-12\n",
      " 9.218865670845844e-10 2.6509905381999488e-12 0.0 0.0 0.0 0.0 0.0\n",
      " -7.494560527732119e-13 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " -4.597211500367848e-11 4.826000710167477e-15 4.133846043252731e-15\n",
      " -1.3740475424128817e-10 -1.906461100098511e-14 4.4395910558936436e-15 0.0]\n"
     ]
    }
   ],
   "source": [
    "# replace missing values by their respective means\n",
    "indices = np.where(data==-999.0)\n",
    "data[indices] = np.take(means, indices[1])\n",
    "# quick check\n",
    "print(np.mean(data, axis= 0)- means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:26.384765Z",
     "start_time": "2020-09-27T18:29:26.205247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.71896381e-13  3.13801390e-14 -6.73309704e-15 -2.73349225e-14\n",
      " -7.22150970e-12 -4.29195303e-12 -1.36881379e-12  6.25675817e-14\n",
      "  7.25006376e-15  3.19039906e-15  1.11030617e-14  3.06481951e-15\n",
      "  3.49239454e-12 -3.19880961e-14  2.90912973e-17  3.03140229e-18\n",
      " -2.48220723e-14 -1.71221062e-18  5.33482394e-16  1.47402030e-14\n",
      " -1.37381464e-17 -1.96827473e-14 -2.76003418e-16  9.70570721e-13\n",
      " -2.20644585e-15 -1.83531436e-15  7.96206825e-12  1.74248055e-14\n",
      " -2.73853080e-15 -1.15462262e-14]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "(225000, 30)\n"
     ]
    }
   ],
   "source": [
    "data = (data - np.mean(data, axis = 0)) / np.std(data, axis=0)\n",
    "print(np.mean(data, axis = 0))\n",
    "print(np.std(data, axis = 0))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add bias column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:29:27.678407Z",
     "start_time": "2020-09-27T18:29:27.636520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225000, 30)\n",
      "(225000, 31)\n",
      "[ 1.00000000e+00 -3.80824516e-13  1.15995991e+00 -8.99007960e-01\n",
      " -8.81846506e-01 -7.22053251e-12 -4.29574198e-12 -1.37006313e-12\n",
      " -1.26937800e+00 -7.68311386e-01 -8.09933495e-01 -7.98411975e-02\n",
      " -1.06261497e+00  3.48733557e-12 -5.08070908e-01 -4.63807470e-01\n",
      "  8.07001953e-01 -4.17125756e-01 -1.23725599e+00  2.63333103e-01\n",
      "  4.40676722e-01 -1.22818043e+00 -9.23426737e-01 -1.00237670e+00\n",
      "  9.77307453e-13 -3.48923968e-15 -2.93908572e-15  7.96425490e-12\n",
      "  1.74008116e-14 -4.53349879e-15 -7.46144441e-01]\n"
     ]
    }
   ],
   "source": [
    "bias_vec = np.ones((data.shape[0],1))\n",
    "print(data.shape)\n",
    "data = np.concatenate((bias_vec, data), axis = 1)\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save TX and Y matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-27T18:32:46.140715Z",
     "start_time": "2020-09-27T18:32:46.070941Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('dataset/preprocessed_tx.npy',data)\n",
    "np.save('dataset/y.npy', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-project1",
   "language": "python",
   "name": "ml-project1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
